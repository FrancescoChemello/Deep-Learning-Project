{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Main libraries\n",
    "\"\"\"\n",
    "import os\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Functions for the onehot encoding\n",
    "\"\"\"\n",
    "\n",
    "def onehot_encoder(dataset):\n",
    "    \"\"\"\n",
    "    Function that encodes a DNA dataset into a onehot encoding dataset.\n",
    "    \"\"\"\n",
    "    onehot_dataset = [dna_onehot_encoder(dna_string) for dna_string in dataset]\n",
    "    onehot_dataset_numpy = np.array(onehot_dataset)\n",
    "\n",
    "    return onehot_dataset_numpy\n",
    "\n",
    "\n",
    "def dna_onehot_encoder(dna_sequence):\n",
    "    \"\"\"\n",
    "    Function that encodes a single DNA string into a onehot encoding string.\n",
    "    \"\"\"\n",
    "    onehot_dict = {\n",
    "        'A' : [1, 0, 0, 0],\n",
    "        'C' : [0, 1, 0, 0],\n",
    "        'G' : [0, 0, 1, 0],\n",
    "        'T' : [0, 0, 0, 1]\n",
    "    }\n",
    "    encoder = [onehot_dict[nuc] for nuc in dna_sequence]\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Net (nn.Module):\n",
    "    def __init__ (self):\n",
    "        super(LSTM_Net, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=128, num_layers=6, batch_first=True, dropout=0.5, bidirectional=True)\n",
    "        # self.lstm = nn.LSTM(input_size=4, hidden_size=128, num_layers=2, dropout=0.5, batch_first=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(256, 256)\n",
    "        self.fc2 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x, _ = self.lstm(x)\n",
    "\n",
    "        x = x[:, -1, :]\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_numeric(sequence):\n",
    "    mapping = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
    "    return [mapping[nuc] for nuc in sequence]\n",
    "\n",
    "def numeric_to_sequence(numeric_sequence):\n",
    "    mapping = ['A', 'C', 'G', 'T']\n",
    "    return ''.join([mapping[nuc] for nuc in numeric_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Before oversampling:  (211238,)\n",
      "Before oversampling:  (211238,)\n",
      "After oversampling:  (413544, 300)\n",
      "After oversampling:  (413544,)\n",
      "Shape with DataFrame:  (413544,)\n",
      "Shape with DatFrame:  (413544,)\n",
      "Start one hot encoding for training\n",
      "End one hot encoding for training\n",
      "X_train shape:  torch.Size([413544, 1, 4])\n",
      "Y_train shape:  torch.Size([413544])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "! MAIN\n",
    "\"\"\"\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(), 'data'))\n",
    "rel_path_train = os.path.join(data_dir, 'fullset_train.csv')\n",
    "rel_path_val = os.path.join(data_dir, 'fullset_validation.csv')\n",
    "rel_path_test = os.path.join(data_dir, 'fullset_test.csv')\n",
    "\n",
    "# Training set\n",
    "\n",
    "# Read the input from the csv file\n",
    "train_csv = pd.read_csv(rel_path_train, sep=\",\")\n",
    "# Drop the NaN values\n",
    "train_csv = train_csv.dropna()\n",
    "# Describe the data\n",
    "# print(train_csv.describe())\n",
    "\n",
    "# Get the data from the csv file\n",
    "train_data = train_csv.values\n",
    "# m = number of input samples\n",
    "m = train_data.shape[0]\n",
    "\n",
    "# Dataframe\n",
    "data = {'sequence' : train_data[:m,1],\n",
    "        'label' : train_data[:m,2].astype(np.int32) }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "count_class_0, count_class_1 = df['label'].value_counts()\n",
    "\n",
    "df_class_0 = df[df['label'] == 0]\n",
    "df_class_1 = df[df['label'] == 1]\n",
    "\n",
    "X_train = df['sequence'].values\n",
    "y_train = df['label'].values\n",
    "\n",
    "print(\"Before oversampling: \", X_train.shape)\n",
    "print(\"Before oversampling: \", y_train.shape)\n",
    "\n",
    "#Convert the sequences to numeric\n",
    "numeric_train = [sequence_to_numeric(seq) for seq in X_train]\n",
    "numeric_train = np.array(numeric_train)\n",
    "\n",
    "# Reshape the data\n",
    "n_samples, _ = numeric_train.shape\n",
    "numeric_train_sequences = numeric_train.reshape((n_samples, -1))\n",
    "\n",
    "# Apply the SMOTE algorithm to balance the dataset\n",
    "smote = SMOTE()\n",
    "X_train, y_train = smote.fit_resample(numeric_train_sequences, y_train)\n",
    "print(\"After oversampling: \", X_train.shape)\n",
    "print(\"After oversampling: \", y_train.shape)\n",
    "\n",
    "data = {'sequence' : X_train[:, 0] , 'label' : y_train}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X_train = df['sequence'].values\n",
    "y_train = df['label'].values\n",
    "\n",
    "print(\"Shape with DataFrame: \", X_train.shape)\n",
    "print(\"Shape with DatFrame: \", y_train.shape)\n",
    "\n",
    "# Convert the sequences to onehot encoding\n",
    "X_train = numeric_to_sequence(X_train)\n",
    "X_train = X_train.reshape(X_train.shape[0], 300)\n",
    "print(\"Start one hot encoding for training\")\n",
    "X_train = onehot_encoder(X_train)\n",
    "print(\"End one hot encoding for training\")\n",
    "\n",
    "X_train = th.from_numpy(X_train).to(device)\n",
    "Y_train = th.tensor(y_train).to(device)\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Class to create a Data Loader with X label and Y label together\n",
    "\"\"\"\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return data_point, label\n",
    "\n",
    "# Create the Dataset\n",
    "train_dataset = CreateDataset(X_train, Y_train)\n",
    "# val_dataset = CreateDataset(X_val, Y_val)\n",
    "# test_dataset = CreateDataset(X_test, Y_test)\n",
    "\n",
    "# Batch size\n",
    "batch_dim = 128\n",
    "\n",
    "# Create the Data Loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_dim, shuffle=True)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=batch_dim, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=batch_dim, shuffle=True)\n",
    "\n",
    "# Free memory\n",
    "del X_train  #, X_val, Y_val, X_test\n",
    "gc.collect()\n",
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the LSTM\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Calculated padded input size per channel: (1). Kernel size: (3). Kernel size can't be greater than actual input size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m Y_batch \u001b[38;5;241m=\u001b[39m Y_batch\u001b[38;5;241m.\u001b[39mlong()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_LSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, Y_batch\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 17\u001b[0m, in \u001b[0;36mLSTM_Net.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m     18\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x)))\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)))\n",
      "File \u001b[1;32mc:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:310\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pietr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\conv.py:306\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    304\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    305\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Calculated padded input size per channel: (1). Kernel size: (3). Kernel size can't be greater than actual input size"
     ]
    }
   ],
   "source": [
    "print(\"Start training the LSTM\")\n",
    "\n",
    "# Model, loss function and optimizer\n",
    "model_LSTM = LSTM_Net().to(device)\n",
    "# criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = th.optim.Adam(model_LSTM.parameters(), lr=0.001)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 5  # CHECK THE VALUE!!\n",
    "best_val_loss = float('inf')\n",
    "counter = 0\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 100  # Hope to reach convergence before 100 epoches\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_LSTM.train()\n",
    "    running_loss = 0.0\n",
    "    i = 0\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "\n",
    "        X_batch = X_batch.float().to(device)\n",
    "        Y_batch = Y_batch.long().to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model_LSTM(X_batch.to(device))\n",
    "        loss = criterion(outputs, Y_batch.to(device))\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        i += 1\n",
    "\n",
    "        \"\"\"\n",
    "        scaler = th.cuda.amp.GradScaler()\n",
    "        with th.cuda.amp.autocast():\n",
    "          outputs = model_LSTM(X_batch.to(device))\n",
    "          loss = criterion(outputs, Y_batch.to(device))\n",
    "\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\"\"\"\n",
    "\n",
    "        # Free memory\n",
    "        del X_batch, Y_batch\n",
    "        th.cuda.empty_cache()\n",
    "    running_loss = running_loss/i\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss:.4f}s')\n",
    "\"\"\"\n",
    "    # Validation\n",
    "    model_LSTM.eval()\n",
    "    val_loss = 0.0\n",
    "    j = 0\n",
    "    with th.no_grad():\n",
    "        for X_batch, Y_batch in val_loader:\n",
    "            X_batch = X_batch.float()\n",
    "            Y_batch = Y_batch.long()\n",
    "\n",
    "            outputs = model_LSTM(X_batch.to(device))\n",
    "            loss = criterion(outputs, Y_batch.to(device))\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            j += 1\n",
    "\n",
    "            # Free memory\n",
    "            del X_batch, Y_batch\n",
    "            th.cuda.empty_cache()\n",
    "\n",
    "    # Losses\n",
    "    running_loss = running_loss/i\n",
    "    val_loss = val_loss/j\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {running_loss:.4f}, Val Loss: {val_loss:.4f}')\n",
    "\n",
    "    # Check for early stopping\n",
    "    if val_loss <= best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\"\"\"\n",
    "print(\"End training the LSTM\")\n",
    "\n",
    "# Free memory\n",
    "del i, j, running_loss #, val_loss\n",
    "gc.collect()\n",
    "th.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
